{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Assignment 4\n",
    "\n",
    "This assignment focuses on exploring and implementing advanced concepts and techniques in information retrieval. The primary objectives are to build Retrieval Augumentation Generation, and learn about Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter your details below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banner ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub Link of your Assingment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 : Setting up the libraries and the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USE_TF\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (25.1.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1.1\n",
      "    Uninstalling pip-25.1.1:\n",
      "      Successfully uninstalled pip-25.1.1\n",
      "Successfully installed pip-25.2\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.12\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting keras==2.12\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow==2.12)\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (25.2.10)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.14.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.23)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (18.1.1)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading numpy-1.23.5-cp310-cp310-win_amd64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (4.21.12)\n",
      "Requirement already satisfied: setuptools in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (66.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (4.14.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.74.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.31.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.40.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.1.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.45.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.6.1)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (1.10.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.0.2)\n",
      "Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 9.5 MB/s  0:00:00\n",
      "Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "   ---------------------------------------- 0.0/272.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/272.8 MB 13.7 MB/s eta 0:00:20\n",
      "    --------------------------------------- 5.8/272.8 MB 14.1 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 9.7/272.8 MB 15.5 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 13.6/272.8 MB 16.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 17.0/272.8 MB 16.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 21.2/272.8 MB 17.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 24.9/272.8 MB 17.3 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 29.1/272.8 MB 17.6 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 33.0/272.8 MB 17.6 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 36.7/272.8 MB 17.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 39.8/272.8 MB 17.5 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 43.8/272.8 MB 17.5 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 46.7/272.8 MB 17.4 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 49.5/272.8 MB 17.0 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 53.5/272.8 MB 17.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 56.9/272.8 MB 17.0 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 60.0/272.8 MB 16.9 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 64.2/272.8 MB 17.1 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 66.8/272.8 MB 16.8 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 70.3/272.8 MB 16.7 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 72.9/272.8 MB 16.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 76.3/272.8 MB 16.5 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 80.0/272.8 MB 16.6 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 83.1/272.8 MB 16.5 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 86.8/272.8 MB 16.5 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 91.0/272.8 MB 16.5 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 95.2/272.8 MB 16.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 98.8/272.8 MB 16.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 102.0/272.8 MB 16.6 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 105.6/272.8 MB 16.7 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 109.1/272.8 MB 16.7 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 113.0/272.8 MB 16.7 MB/s eta 0:00:10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
      "tensorflow-cpu 2.15.0 requires tensorflow-intel==2.15.0; platform_system == \"Windows\", but you have tensorflow-intel 2.12.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ---------------- ---------------------- 116.4/272.8 MB 16.7 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 120.3/272.8 MB 16.8 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 124.0/272.8 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 127.9/272.8 MB 16.9 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 131.9/272.8 MB 16.9 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 135.8/272.8 MB 17.0 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 139.7/272.8 MB 17.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 143.9/272.8 MB 17.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 147.1/272.8 MB 17.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 150.5/272.8 MB 17.0 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 154.4/272.8 MB 17.1 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 157.3/272.8 MB 17.0 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 160.7/272.8 MB 17.0 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 164.1/272.8 MB 17.0 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 167.2/272.8 MB 17.0 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 170.1/272.8 MB 16.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 174.3/272.8 MB 17.0 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 177.7/272.8 MB 17.0 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 181.7/272.8 MB 17.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 185.9/272.8 MB 17.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 189.5/272.8 MB 17.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 192.4/272.8 MB 17.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 196.6/272.8 MB 17.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 200.8/272.8 MB 17.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 203.9/272.8 MB 17.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 207.4/272.8 MB 17.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 211.0/272.8 MB 17.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 214.7/272.8 MB 17.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 218.6/272.8 MB 17.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 222.0/272.8 MB 17.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 225.7/272.8 MB 17.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 229.4/272.8 MB 17.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 233.3/272.8 MB 17.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 237.5/272.8 MB 17.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 239.9/272.8 MB 17.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 244.1/272.8 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 247.7/272.8 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 251.4/272.8 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 255.9/272.8 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 260.0/272.8 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 263.7/272.8 MB 17.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  267.1/272.8 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  270.8/272.8 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.6/272.8 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.6/272.8 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.6/272.8 MB 17.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 272.8/272.8 MB 16.8 MB/s  0:00:16\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.4/14.6 MB 18.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.6/14.6 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.0/14.6 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 15.9 MB/s  0:00:00\n",
      "Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 4.2/5.6 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 20.3 MB/s  0:00:00\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.3 MB/s  0:00:00\n",
      "Installing collected packages: tf-keras, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "   ---------------------------------------- 0/9 [tf-keras]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "  Attempting uninstall: numpy\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "    Found existing installation: numpy 1.24.4\n",
      "   ---- ----------------------------------- 1/9 [tensorflow-estimator]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "    Uninstalling numpy-1.24.4:\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "  Attempting uninstall: keras\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "    Found existing installation: keras 2.15.0\n",
      "   -------- ------------------------------- 2/9 [numpy]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "    Uninstalling keras-2.15.0:\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "  Attempting uninstall: gast\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "    Found existing installation: gast 0.6.0\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "    Uninstalling gast-0.6.0:\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "      Successfully uninstalled gast-0.6.0\n",
      "   ------------- -------------------------- 3/9 [keras]\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "    Found existing installation: google-auth-oauthlib 1.2.2\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "    Uninstalling google-auth-oauthlib-1.2.2:\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "  Attempting uninstall: tensorboard\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "    Found existing installation: tensorboard 2.15.2\n",
      "   ----------------- ---------------------- 4/9 [gast]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "    Uninstalling tensorboard-2.15.2:\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "      Successfully uninstalled tensorboard-2.15.2\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "    Found existing installation: tensorflow-intel 2.15.0\n",
      "   -------------------------- ------------- 6/9 [tensorboard]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "    Uninstalling tensorflow-intel-2.15.0:\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "      Successfully uninstalled tensorflow-intel-2.15.0\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ------------------------------- -------- 7/9 [tensorflow-intel]\n",
      "   ---------------------------------------- 9/9 [tensorflow]\n",
      "\n",
      "Successfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tf-keras-2.15.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.1)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.1%2Bcpu-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.1%2Bcpu-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.1%2Bcpu-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.1 MB/s  0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.1%2Bcpu-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 17.7 MB/s  0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   ---------------------------------------- 2/2 [torchaudio]\n",
      "\n",
      "Successfully installed torchaudio-2.7.1+cpu torchvision-0.22.1+cpu\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-1.98.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.4.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.42-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.7.34-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.11.1-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (14.1.0)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Using cached jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.21.12)\n",
      "Requirement already satisfied: sympy in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.9 MB/s  0:00:00\n",
      "Downloading sqlalchemy-2.0.42-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 8.5 MB/s  0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
      "Using cached huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/14.9 MB 9.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.9/14.9 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.9 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.4/14.9 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 13.0 MB/s  0:00:01\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 894.0/894.0 kB 19.7 MB/s  0:00:00\n",
      "Using cached openai-1.98.0-py3-none-any.whl (767 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Using cached chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl (452 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl (296 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached langsmith-0.4.9-py3-none-any.whl (369 kB)\n",
      "Downloading orjson-3.11.1-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Downloading mmh3-5.2.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.22.1-cp310-cp310-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.9/12.7 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.7 MB 20.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.7 MB 20.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 18.9 MB/s  0:00:00\n",
      "Using cached opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.2/26.2 MB 21.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.9/26.2 MB 22.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.9/26.2 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.2 MB 22.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.2 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 21.6 MB/s  0:00:01\n",
      "Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2025.7.34-cp310-cp310-win_amd64.whl (276 kB)\n",
      "Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl (231 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading scikit_learn-1.7.1-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 4.7/8.9 MB 23.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 24.1 MB/s  0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=dfeb56a3c6b14878b4c5513dfaa0dc86a761a4836fc377e975eba71d67f1efad\n",
      "  Stored in directory: c:\\users\\parth\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, zstandard, xxhash, websockets, websocket-client, typing-inspection, threadpoolctl, tenacity, sniffio, shellingham, safetensors, rpds-py, regex, pyreadline3, pyproject_hooks, pydantic-core, pybase64, pyarrow, protobuf, propcache, overrides, orjson, numpy, multidict, mmh3, jsonpointer, joblib, jiter, importlib-metadata, httptools, h11, greenlet, fsspec, frozenlist, distro, dill, bcrypt, backoff, async-timeout, annotated-types, aiohappyeyeballs, yarl, uvicorn, tiktoken, SQLAlchemy, requests-toolbelt, referencing, pydantic, posthog, opentelemetry-proto, opentelemetry-api, multiprocess, jsonpatch, humanfriendly, huggingface-hub, httpcore, googleapis-common-protos, faiss-cpu, build, anyio, aiosignal, watchfiles, typer, tokenizers, scikit-learn, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, jsonschema-specifications, httpx, coloredlogs, aiohttp, transformers, opentelemetry-sdk, openai, onnxruntime, langsmith, jsonschema, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, langchain-core, datasets, langchain-text-splitters, chromadb, langchain\n",
      "\n",
      "    ---------------------------------------  2/86 [zstandard]\n",
      "   - --------------------------------------  4/86 [websockets]\n",
      "   -- -------------------------------------  5/86 [websocket-client]\n",
      "   --- ------------------------------------  7/86 [threadpoolctl]\n",
      "   ----- ---------------------------------- 11/86 [safetensors]\n",
      "   ------ --------------------------------- 13/86 [regex]\n",
      "   ------ --------------------------------- 14/86 [pyreadline3]\n",
      "   ------ --------------------------------- 14/86 [pyreadline3]\n",
      "   ------- -------------------------------- 17/86 [pybase64]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "  Attempting uninstall: protobuf\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "   -------- ------------------------------- 18/86 [pyarrow]\n",
      "   -------- ------------------------------- 19/86 [protobuf]\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "   -------- ------------------------------- 19/86 [protobuf]\n",
      "   -------- ------------------------------- 19/86 [protobuf]\n",
      "   -------- ------------------------------- 19/86 [protobuf]\n",
      "   --------- ------------------------------ 20/86 [propcache]\n",
      "  Attempting uninstall: numpy\n",
      "   --------- ------------------------------ 20/86 [propcache]\n",
      "    Found existing installation: numpy 1.23.5\n",
      "   --------- ------------------------------ 20/86 [propcache]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "    Uninstalling numpy-1.23.5:\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ---------- ----------------------------- 23/86 [numpy]\n",
      "   ------------ --------------------------- 27/86 [joblib]\n",
      "   ------------ --------------------------- 27/86 [joblib]\n",
      "   ------------ --------------------------- 27/86 [joblib]\n",
      "   ------------- -------------------------- 28/86 [jiter]\n",
      "   -------------- ------------------------- 31/86 [h11]\n",
      "   -------------- ------------------------- 32/86 [greenlet]\n",
      "  Attempting uninstall: fsspec\n",
      "   -------------- ------------------------- 32/86 [greenlet]\n",
      "    Found existing installation: fsspec 2025.7.0\n",
      "   -------------- ------------------------- 32/86 [greenlet]\n",
      "    Uninstalling fsspec-2025.7.0:\n",
      "   -------------- ------------------------- 32/86 [greenlet]\n",
      "      Successfully uninstalled fsspec-2025.7.0\n",
      "   -------------- ------------------------- 32/86 [greenlet]\n",
      "   --------------- ------------------------ 33/86 [fsspec]\n",
      "   --------------- ------------------------ 33/86 [fsspec]\n",
      "   --------------- ------------------------ 33/86 [fsspec]\n",
      "   ---------------- ----------------------- 36/86 [dill]\n",
      "   ----------------- ---------------------- 37/86 [bcrypt]\n",
      "   ------------------- -------------------- 42/86 [yarl]\n",
      "   -------------------- ------------------- 43/86 [uvicorn]\n",
      "   -------------------- ------------------- 44/86 [tiktoken]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   -------------------- ------------------- 45/86 [SQLAlchemy]\n",
      "   --------------------- ------------------ 46/86 [requests-toolbelt]\n",
      "   --------------------- ------------------ 47/86 [referencing]\n",
      "   ---------------------- ----------------- 48/86 [pydantic]\n",
      "   ---------------------- ----------------- 48/86 [pydantic]\n",
      "   ---------------------- ----------------- 48/86 [pydantic]\n",
      "   ---------------------- ----------------- 48/86 [pydantic]\n",
      "   ---------------------- ----------------- 48/86 [pydantic]\n",
      "   ---------------------- ----------------- 49/86 [posthog]\n",
      "   ---------------------- ----------------- 49/86 [posthog]\n",
      "   ----------------------- ---------------- 50/86 [opentelemetry-proto]\n",
      "   ----------------------- ---------------- 51/86 [opentelemetry-api]\n",
      "   ------------------------ --------------- 52/86 [multiprocess]\n",
      "   ------------------------ --------------- 52/86 [multiprocess]\n",
      "   ------------------------- -------------- 54/86 [humanfriendly]\n",
      "   ------------------------- -------------- 55/86 [huggingface-hub]\n",
      "   ------------------------- -------------- 55/86 [huggingface-hub]\n",
      "   ------------------------- -------------- 55/86 [huggingface-hub]\n",
      "   ------------------------- -------------- 55/86 [huggingface-hub]\n",
      "   ------------------------- -------------- 55/86 [huggingface-hub]\n",
      "   -------------------------- ------------- 56/86 [httpcore]\n",
      "   -------------------------- ------------- 57/86 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 57/86 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 57/86 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 58/86 [faiss-cpu]\n",
      "   -------------------------- ------------- 58/86 [faiss-cpu]\n",
      "   -------------------------- ------------- 58/86 [faiss-cpu]\n",
      "   -------------------------- ------------- 58/86 [faiss-cpu]\n",
      "   --------------------------- ------------ 60/86 [anyio]\n",
      "   ---------------------------- ----------- 61/86 [aiosignal]\n",
      "   ----------------------------- ---------- 63/86 [typer]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------------ --------- 65/86 [scikit-learn]\n",
      "   ------------------------- ------- 66/86 [opentelemetry-semantic-conventions]\n",
      "   ------------------------- ------- 66/86 [opentelemetry-semantic-conventions]\n",
      "   ------------------------- ------- 66/86 [opentelemetry-semantic-conventions]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   ------------------------------- -------- 68/86 [kubernetes]\n",
      "   -------------------------------- ------- 69/86 [jsonschema-specifications]\n",
      "   -------------------------------- ------- 70/86 [httpx]\n",
      "   --------------------------------- ------ 72/86 [aiohttp]\n",
      "   --------------------------------- ------ 72/86 [aiohttp]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   --------------------------------- ------ 73/86 [transformers]\n",
      "   ---------------------------------- ----- 74/86 [opentelemetry-sdk]\n",
      "   ---------------------------------- ----- 74/86 [opentelemetry-sdk]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ---------------------------------- ----- 75/86 [openai]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 76/86 [onnxruntime]\n",
      "   ----------------------------------- ---- 77/86 [langsmith]\n",
      "   ----------------------------------- ---- 77/86 [langsmith]\n",
      "   ----------------------------------- ---- 77/86 [langsmith]\n",
      "   ------------------------------------ --- 78/86 [jsonschema]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------ --- 79/86 [sentence-transformers]\n",
      "   ------------------------------------- -- 81/86 [langchain-core]\n",
      "   ------------------------------------- -- 81/86 [langchain-core]\n",
      "   ------------------------------------- -- 81/86 [langchain-core]\n",
      "   ------------------------------------- -- 81/86 [langchain-core]\n",
      "   ------------------------------------- -- 81/86 [langchain-core]\n",
      "   ------------------------------------- -- 81/86 [langchain-core]\n",
      "   -------------------------------------- - 82/86 [datasets]\n",
      "   -------------------------------------- - 82/86 [datasets]\n",
      "   -------------------------------------- - 82/86 [datasets]\n",
      "   -------------------------------------- - 82/86 [datasets]\n",
      "   -------------------------------------- - 82/86 [datasets]\n",
      "   -------------------------------------- - 82/86 [datasets]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  84/86 [chromadb]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------  85/86 [langchain]\n",
      "   ---------------------------------------- 86/86 [langchain]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.42 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 chromadb-1.0.15 coloredlogs-15.0.1 datasets-4.0.0 dill-0.3.8 distro-1.9.0 durationpy-0.10 faiss-cpu-1.11.0.post1 frozenlist-1.7.0 fsspec-2025.3.0 googleapis-common-protos-1.70.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 huggingface-hub-0.34.3 humanfriendly-10.0 importlib-metadata-8.7.0 jiter-0.10.0 joblib-1.5.1 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 langchain-0.3.27 langchain-core-0.3.72 langchain-text-splitters-0.3.9 langsmith-0.4.9 mmh3-5.2.0 multidict-6.6.3 multiprocess-0.70.16 numpy-1.26.4 onnxruntime-1.22.1 openai-1.98.0 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.1 overrides-7.7.0 posthog-5.4.0 propcache-0.3.2 protobuf-6.31.1 pyarrow-21.0.0 pybase64-1.4.2 pydantic-2.11.7 pydantic-core-2.33.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 referencing-0.36.2 regex-2025.7.34 requests-toolbelt-1.0.0 rpds-py-0.26.0 safetensors-0.5.3 scikit-learn-1.7.1 sentence-transformers-5.0.0 shellingham-1.5.4 sniffio-1.3.1 tenacity-9.1.2 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.4 transformers-4.54.1 typer-0.16.0 typing-inspection-0.4.1 uvicorn-0.35.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 xxhash-3.5.0 yarl-1.20.1 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n",
      "tensorflow-metadata 1.17.2 requires protobuf<4.22,>=4.21.6; python_version < \"3.11\", but you have protobuf 6.31.1 which is incompatible.\n",
      "wandb 0.17.0 requires protobuf!=4.21.0,<5,>=3.19.0; sys_platform != \"linux\", but you have protobuf 6.31.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.4.9)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\parth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "\n",
      "   ---------------------- ----------------- 4/7 [pydantic-settings]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------- ----- 6/7 [langchain-community]\n",
      "   ---------------------------------------- 7/7 [langchain-community]\n",
      "\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12 keras==2.12 tf-keras\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "!pip install langchain sentence-transformers transformers faiss-cpu datasets tiktoken openai chromadb\n",
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import FAISS\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from transformers import AutoTokenizer, AutoModel, T5EncoderModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2:  Data Preprocessing and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"pandas\"\n",
    "MODEL_NAME = \"Salesforce/codet5-base\"\n",
    "MAX_TOKENS = 512\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load all .py code files\n",
    "def extract_code_chunks(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    chunks = []\n",
    "    try:\n",
    "        tree = ast.parse(code, filename=file_path)\n",
    "        for node in ast.iter_child_nodes(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                start_line = node.lineno - 1\n",
    "                end_line = node.end_lineno or node.body[-1].lineno  # Python 3.8+ supports end_lineno\n",
    "                chunk = \"\\n\".join(code.splitlines()[start_line:end_line])\n",
    "                chunks.append(chunk)\n",
    "    except Exception as e:\n",
    "        # Fallback to using entire file if parsing fails\n",
    "        chunks = [code]\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_code_chunks_by_function(root_dir):\n",
    "    chunks = []\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                path = os.path.join(subdir, file)\n",
    "                chunks.extend(extract_code_chunks(path))\n",
    "    return chunks\n",
    "\n",
    "code_chunks = load_code_chunks_by_function(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5EncoderModel(\n",
       "  (shared): Embedding(32100, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5EncoderModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Token chunking\n",
    "def chunk_tokens(tokens, max_len=MAX_TOKENS):\n",
    "    return [tokens[i:i+max_len] for i in range(0, len(tokens), max_len)]\n",
    "\n",
    "def tokens_to_text(tokens):\n",
    "    return tokenizer.convert_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare code chunks (safe version with truncation)\n",
    "chunked_texts = []\n",
    "for chunk in code_chunks:\n",
    "    tokens = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=MAX_TOKENS)\n",
    "    text = tokenizer.decode(tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    chunked_texts.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings...\n"
     ]
    }
   ],
   "source": [
    "# 5. Generate embeddings\n",
    "def get_embeddings(texts, tokenizer, model, device=DEVICE, batch_size=BATCH_SIZE):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        encoded = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            hidden_states = outputs.last_hidden_state  # [B, T, H]\n",
    "            mask = encoded['attention_mask'].unsqueeze(-1).expand(hidden_states.size())\n",
    "            summed = torch.sum(hidden_states * mask, dim=1)\n",
    "            counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "            mean_pooled = summed / counts\n",
    "            embeddings.append(mean_pooled.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "print(\"Computing embeddings...\")\n",
    "embeddings = get_embeddings(chunked_texts, tokenizer, model)\n",
    "print(f\"Generated embeddings of shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeT5Embeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"Salesforce/codet5-base\", device=None):\n",
    "        from transformers import AutoTokenizer, T5EncoderModel\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = T5EncoderModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self.embed_query(t) for t in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            hidden_states = outputs.last_hidden_state  # (1, seq_len, hidden_dim)\n",
    "            mask = inputs['attention_mask'].unsqueeze(-1)\n",
    "            summed = torch.sum(hidden_states * mask, dim=1)\n",
    "            counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "            mean_pooled = (summed / counts).squeeze(0)\n",
    "        return mean_pooled.cpu().numpy().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m CodeT5Embeddings()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 3: Build FAISS index from documents using embeddings\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 4: Save index and metadata\u001b[39;00m\n\u001b[0;32m     12\u001b[0m db\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    846\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \n\u001b[0;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1045\u001b[0m         texts,\n\u001b[0;32m   1046\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[45], line 10\u001b[0m, in \u001b[0;36mCodeT5Embeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_query(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "Cell \u001b[1;32mIn[45], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "Cell \u001b[1;32mIn[45], line 15\u001b[0m, in \u001b[0;36mCodeT5Embeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     16\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# (1, seq_len, hidden_dim)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1930\u001b[0m, in \u001b[0;36mT5EncoderModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m    Indices of input sequence tokens in the vocabulary. T5 is a model with relative position embeddings so you\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;124;03m>>> last_hidden_states = outputs.last_hidden_state\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1930\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1933\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1936\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1938\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_outputs\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1092\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m   1090\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m-> 1092\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:681\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    667\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    679\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    680\u001b[0m ):\n\u001b[1;32m--> 681\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    692\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:599\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    589\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m ):\n\u001b[0;32m    598\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 599\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    610\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:511\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk(current_states)\n\u001b[1;32m--> 511\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_value_proj_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    513\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_value_proj_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Save embeddings using FAISS\n",
    "# Convert chunked_texts to Document objects\n",
    "docs = [Document(page_content=text) for text in chunked_texts]  # You already have chunked_texts\n",
    "\n",
    "# Step 2: Initialize embedding model\n",
    "embedding_model = CodeT5Embeddings()\n",
    "\n",
    "# Step 3: Build FAISS index from documents using embeddings\n",
    "db = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "# Step 4: Save index and metadata\n",
    "db.save_local(\"code_index\")\n",
    "print(\" Saved FAISS index and metadata to 'code_index' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Implementing RAG using LangChain for different queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explain the RAG pipeline and all its components \n",
    "RAG (Retrieval-Augmented Generation) combines two parts:\n",
    "\n",
    "Retriever: Looks up relevant content from an external knowledge base (in this case, source code).\n",
    "\n",
    "Generator: Uses the retrieved content to answer questions more accurately.\n",
    "\n",
    "In my implementation:\n",
    "\n",
    "*   I load all Python source files from the pandas/ repo.\n",
    "\n",
    "*   I use Salesforce/codet5-base (a code-aware encoder model) to generate dense embeddings for each truncated code chunk.\n",
    "\n",
    "*   These embeddings are stored in a FAISS vector index, allowing fast nearest-neighbor search.\n",
    "\n",
    "*   At query time, the user asks a natural language question. The system:\n",
    "\n",
    "*   *   Embeds the query using the same model,\n",
    "\n",
    "*   *   Retrieves the most similar code chunks via FAISS,\n",
    "\n",
    "*   *   Sends the context + query to a generator model (e.g., LLM via LangChain) to answer it.\n",
    "\n",
    "LangChain is used to manage the flow: document loading  embedding  retrieval  generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pretrained model used and justification (1 mark)\n",
    "I selected Salesforce/codet5-base, a transformer encoder specialized for source code. Key reasons:\n",
    "\n",
    "*   Pretrained on large code datasets like CodeSearchNet.\n",
    "\n",
    "*   Understands code structure and semantics.\n",
    "\n",
    "*   Produces meaningful embeddings for code, ideal for similarity search.\n",
    "\n",
    "*   It aligns well with my goal: building an intelligent system to query a codebase like pandas using natural language.\n",
    "\n",
    "This is also a project I plan to expand and eventually include on my resume. Its been a fun and insightful exercise in combining NLP with software engineering tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Set up the RAG pipeline using LangChain (2 marks)\n",
    "I used LangChain to integrate:\n",
    "\n",
    "*  Document Loader: Loads all .py files from the pandas/ repo.\n",
    "\n",
    "*  Splitter: Token truncation ensures all code fits within model limits (MAX_TOKENS = 512).\n",
    "\n",
    "*  Embedder: T5EncoderModel (from Salesforce/codet5-base) is used to create vector representations of code.\n",
    "\n",
    "*  Retriever: FAISS index stores embeddings for fast similarity-based retrieval.\n",
    "\n",
    "*  LangChain Chain: Wires together the retriever and an LLM (e.g., CodeT5 for generation or another model like GPT-3.5) for final response generation.\n",
    "\n",
    "I save the FAISS index (code_index.faiss) for persistent use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Q: How does pandas handle missing data?\n",
      "Retrieved snippets:\n",
      "Doc 1 snippet: __all__ = [\"eval\"]\n",
      "from pandas.core.computation.eval import eval\n",
      " \n",
      "---\n",
      "Doc 2 snippet: from typing import Any\n",
      "\n",
      "from pandas import Index\n",
      "\n",
      "\n",
      "def allow_na_ops(obj: Any) -> bool:\n",
      "    \"\"\"Whether to skip test cases including NaN\"\"\"\n",
      "    is_bool_index = isinstance(obj, Index) and obj.inferred_type == \"boolean\"\n",
      "    return not is_bool_index and obj._can_hold_na\n",
      " \n",
      "---\n",
      "Doc 3 snippet: \"\"\"Pandas benchmarks.\"\"\"\n",
      " \n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth\\AppData\\Local\\Temp\\ipykernel_192432\\3328273058.py:26: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you don't know the answer,you\n",
      "\n",
      "---\n",
      "Q: Where is the DataFrame class defined?\n",
      "Retrieved snippets:\n",
      "Doc 1 snippet: __all__ = [\"eval\"]\n",
      "from pandas.core.computation.eval import eval\n",
      " \n",
      "---\n",
      "Doc 2 snippet: \"\"\"Pandas benchmarks.\"\"\"\n",
      " \n",
      "---\n",
      "Doc 3 snippet: from pandas.io.sas.sasreader import read_sas\n",
      "\n",
      "__all__ = [\"read_sas\"]\n",
      " \n",
      "---\n",
      "A: is the DataFrame class defined?the DataFrame class defined?  def) :()() )() )( )( ) )( )( ) )( ) )( )( ) )( ) )( ) )( ) )( )( )( ) )( )( )( )( ) )\n",
      "\n",
      "---\n",
      "Q: Which file contains code for reading CSV files?\n",
      "Retrieved snippets:\n",
      "Doc 1 snippet: __all__ = [\"eval\"]\n",
      "from pandas.core.computation.eval import eval\n",
      " \n",
      "---\n",
      "Doc 2 snippet: \"\"\"Pandas benchmarks.\"\"\"\n",
      " \n",
      "---\n",
      "Doc 3 snippet: from pandas.io.sas.sasreader import read_sas\n",
      "\n",
      "__all__ = [\"read_sas\"]\n",
      " \n",
      "---\n",
      "A: ()( )( ) )( )( )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( ) )( )( ) )\n",
      "\n",
      "---\n",
      "Q: How is groupby implemented in pandas?\n",
      "Retrieved snippets:\n",
      "Doc 1 snippet: __all__ = [\"eval\"]\n",
      "from pandas.core.computation.eval import eval\n",
      " \n",
      "---\n",
      "Doc 2 snippet: \"\"\"Pandas benchmarks.\"\"\"\n",
      " \n",
      "---\n",
      "Doc 3 snippet: from pandas.io.sas.sasreader import read_sas\n",
      "\n",
      "__all__ = [\"read_sas\"]\n",
      " \n",
      "---\n",
      "A: pandas.core.computation.eval import eval\n",
      "\n",
      "__all__pandas.core.computation.eval import eval\n",
      "\n",
      "__all__pandas.core.computation.eval import eval\n",
      "\n",
      "__all__pandas.core.computation.eval import eval\n",
      "\n",
      "__all__pandas.core.computation.eval import eval\n",
      "\n",
      "__all__pandas.core.computation.evalpandas.core.computation.eval\n",
      "\n",
      "---\n",
      "Q: Is there any functionality related to time series?\n",
      "Retrieved snippets:\n",
      "Doc 1 snippet: __all__ = [\"eval\"]\n",
      "from pandas.core.computation.eval import eval\n",
      " \n",
      "---\n",
      "Doc 2 snippet: \"\"\"Pandas benchmarks.\"\"\"\n",
      " \n",
      "---\n",
      "Doc 3 snippet: from pandas.io.sas.sasreader import read_sas\n",
      "\n",
      "__all__ = [\"read_sas\"]\n",
      " \n",
      "---\n",
      "A: is there any functionality relatedto time series?  def) :() )( )( ) )( ) )( )( ) )( )( )( ) )( ) )( )( ) )( ) )( ) )( ) )( )( ) )( ) )( ) )( ) )( )( )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_model = CodeT5Embeddings()\n",
    "db = FAISS.load_local(\"code_index\", embedding_model,allow_dangerous_deserialization=True)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-base\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=256)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Create the RAG-style chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
    "\n",
    "# Define meaningful queries about the codebase\n",
    "questions = [\n",
    "    \"How does pandas handle missing data?\",\n",
    "    \"Where is the DataFrame class defined?\",\n",
    "    \"Which file contains code for reading CSV files?\",\n",
    "    \"How is groupby implemented in pandas?\",\n",
    "    \"Is there any functionality related to time series?\"\n",
    "]\n",
    "\n",
    "# Ask questions and print responses\n",
    "for question in questions:\n",
    "    print(f\"---\\nQ: {question}\")\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    print(\"Retrieved snippets:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Doc {i+1} snippet:\", doc.page_content[:300], \"\\n---\")\n",
    "    result = qa_chain.run(question)\n",
    "    print(f\"A: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 : Modify and evaluate the different components of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Selecting and implementing a pretrained model for a new task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
